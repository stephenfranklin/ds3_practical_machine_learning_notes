---
title       : Training options
subtitle    : 
author      : Jeffrey Leek
job         : Johns Hopkins Bloomberg School of Public Health
logo        : bloomberg_shield.png
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow   # 
url:
  lib: ../../librariesNew
  assets: ../../assets
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# make this an external chunk that can be included in any file
options(width = 100)
require(knitr)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig_012_training/')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```


## SPAM Example
Here we have a basic caret example with default options.
```{r libraries,cache=F}
library(caret); library(kernlab); data(spam)
```
Note: In knitr, libraries should not be cached if you want to use them with other chunks.
```{r loadPackage,cache=TRUE}
inTrain <- createDataPartition(y=spam$type,
                              p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~.,data=training, method="glm")
```

---

## Train options
Here are some options for the `train()` function.
```{r ,dependson="loadPackage"}
args(train.default)
```

- `preProcess`: preprocessing options.
- `weights`: upweight or downweight certain observations,
    - useful if you have an unbalanced training set with a lot more examples of one type than another. 
- `metric`: default for factor variables is accuracy; for continuous variables, it's root mean squared error (RMSE).
- `trControl`: uses the `traincontrol()` function for various control parameters.

---

## Metric options

__Continous outcomes__:

  * _RMSE_ = Root mean squared error
  * _RSquared_ = $R^2$ from regression models;
    * it's a measure of linear agreement; useful for Linear Regression; less useful for Random Forest.

__Categorical outcomes__:

  * _Accuracy_ = Fraction correct
  * _Kappa_ = A measure of [concordance](http://en.wikipedia.org/wiki/Cohen%27s_kappa)

--- 

## trainControl

```{r , dependson="loadPackage",cache=TRUE}
args(trainControl)
```

--- 

## trainControl resampling
The `trainControl()` argument allows you to be much more precise in the way you train models.
* _method_
  * _boot_ = bootstrapping
  * _boot632_ = bootstrapping with adjustment
  * _cv_ = cross validation
  * _repeatedcv_ = repeated cross validation (See _repeats_.)
    * sub-cross validation with different random draws.
  * _LOOCV_ = leave one out cross validation.
  * Remember that there is a bias-variance trade-off between using a large number of folds and a small number of folds.
* _number_
  * For boot/cross validation
  * Number of subsamples to take
* _repeats_
  * Number of times to repeate subsampling
  * If big this can _slow things down_

---

## Setting the seed

* It is often useful to set an overall seed.
* You can also set a seed for each resample.
    * There is a `seed` argument in the `trainControl` function.
* Seeding each resample is useful for parallel fits.

--- 

## seed example

```{r , dependson="seedExample",cache=TRUE}
set.seed(1235)
modelFit2 <- train(type ~.,data=training, method="glm")
modelFit2
```


--- 

## seed example

```{r , dependson="seedExample",cache=TRUE}
set.seed(1235)
modelFit3 <- train(type ~.,data=training, method="glm")
modelFit3
```


--- 

## Further resources

* [Caret tutorial](http://www.edii.uclm.es/~useR-2013/Tutorials/kuhn/user_caret_2up.pdf)
* [Model training and tuning](http://caret.r-forge.r-project.org/training.html)
