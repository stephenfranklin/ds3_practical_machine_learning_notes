---
title       : Preprocessing
subtitle    : 
author      : Jeffrey Leek
job         : Johns Hopkins Bloomberg School of Public Health
logo        : bloomberg_shield.png
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow   # 
url:
  lib: ../../libraries
  assets: ../../assets
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
---


```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# make this an external chunk that can be included in any file
options(width = 100)
require(knitr)
opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig_014_preprocess/')

options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knit_hooks$set(plot = knitr:::hook_plot_html)
```


## Why preprocess?

```{r libraries, cache=FALSE}
library(caret); library(kernlab); library(RANN)
```
```{r loadPackage,cache=TRUE,fig.height=3.5,fig.width=3.5}
data(spam) ## from kernlab
inTrain <- createDataPartition(y=spam$type,
                              p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
```
Here we've made a histogram of the frequency of emails with different run lengths of capital letters, i.e. "THIS EMAIL IS ALL CAPS SO BUY SOMETHING NOW." 

Nearly all of the emails have short run lengths, but there are a few that are much longer. This is an example of a variable that is very skewed, which makes it difficult to deal with in model based predictors, so we'll preprocess.

---

## Why preprocess?
The standard deviation here is much much larger than the mean.

```{r ,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=3.5}
mean(training$capitalAve)
sd(training$capitalAve)
```

---

## Standardizing

Standardizing will turn the mean into 0 and the sd into 1.
```{r ,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=3.5}
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve  - mean(trainCapAve))/sd(trainCapAve) 
mean(trainCapAveS)
sd(trainCapAveS)
```

---

## Standardizing - test set
To standardize the test set, we **must** use the mean and sd from the training set.

```{r ,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=3.5}
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve) 
mean(testCapAveS)
sd(testCapAveS)
```
Hopefully the standardized test mean and sd will be close to 0 and 1, as they are here.

---

## Standardizing - _preProcess_ function
The caret package has a `preProcess()` function which can easily standardize the data. We'll create an object (we'll call `preObj`) which contains the parameters we want to use to preprocess the data. We pass the parameter `method` the functions "center" and "scale". And then we can apply that to our training set with `predict()`.

```{r preprocess,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=3.5}
preObj <- preProcess(training[,-58],method=c("center","scale"))  ## column 58 is the outcome variable, so we eliminate that one.
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
```

---

## Standardizing - _preProcess_ function
We can also use `preObj` to apply that same preprocessing to the test set.   
```{r ,dependson="preprocess",cache=TRUE,fig.height=3.5,fig.width=3.5}
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
```

---

## Standardizing - _preProcess_ argument
You can also pass the preProcess commands directly to the `train()` function as an argument.

```{r training, dependson="loadPackage",cache=TRUE}
set.seed(32343)
modelFit <- train(type ~.,data=training,
                  preProcess=c("center","scale"),method="glm")
modelFit
```


---

## Standardizing - Box-Cox transforms

```{r ,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=7}
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
```


---

## Standardizing - Imputing data

```{r knn,dependson="loadPackage",cache=TRUE,fig.height=3.5,fig.width=7}
set.seed(13343)

# Make some values NA
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA

# Impute and standardize
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve

# Standardize true values
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
```


---

## Standardizing - Imputing data

```{r ,dependson="knn",cache=TRUE,fig.height=3.5,fig.width=7}
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
```

---

## Notes and further reading

* Training and test must be processed in the same way
* Test transformations will likely be imperfect
  * Especially if the test/training sets collected at different times
* Careful when transforming factor variables!
* [preprocessing with caret](http://caret.r-forge.r-project.org/preprocess.html)